# Line Instance Grouping via Pixel Embeddings

Модель решает задачу instance-segmentation линий на графиках через пиксельные эмбеддинги и кластеризацию, без фиксированного числа линий.

## Задача

Есть изображение графика и пиксели-кандидаты линии. Нужно разнести эти пиксели по отдельным линиям (инстансам), даже если число линий заранее неизвестно.

## Идея подхода

Вместо прямого предсказания масок линий модель предсказывает эмбеддинг-вектор для каждого пикселя:

- пиксели одной линии имеют близкие эмбеддинги;
- пиксели разных линий имеют разные эмбеддинги.

После этого выполняется кластеризация эмбеддингов (например, DBSCAN), и кластеры интерпретируются как отдельные линии.

## Вход и выход модели

- Вход: `img` размера `3 x H x W` (RGB).
- Выход: `emb` размера `D x h x w` (в коде `emb_dim=8` по умолчанию).

Важно: из-за pooling/upsampling пространственный размер выхода может отличаться на 1 пиксель. В `main.py` это учитывается обрезкой `inst/valid` до размера `emb`.

## Архитектура

Используется компактный U-Net (`SmallUNet`):

- Encoder: блоки `Conv-BN-ReLU` + `MaxPool`, извлечение признаков и рост receptive field.
- Bottleneck: самый глубокий блок признаков.
- Decoder: `ConvTranspose` + skip-connections из encoder для восстановления деталей тонких линий.
- Head: `1x1 Conv` для проекции в эмбеддинг-пространство (`emb_dim` каналов).

## Формирование таргетов

Из COCO-like JSON формируются:

- `instance_mask (H x W)`: ID линии (`1..K`, `0` — фон).
- `valid_mask (H x W)`: валидные пиксели для лосса.

Полилинии растризуются через `cv2.polylines(...)` с настраиваемой толщиной (`--thickness`).  
Зоны overlap между линиями исключаются из `valid_mask`, чтобы не портить supervision неоднозначными пикселями.

## Loss: Discriminative Embedding Loss

Используется классическая discriminative loss для инстанс-эмбеддингов:

- Variance term: стягивает эмбеддинги внутри каждого инстанса к его центроиду.
- Distance term: раздвигает центроиды разных инстансов.
- Regularization term: ограничивает нормы центроидов.

Таким образом модель обучает геометрию эмбеддинг-пространства, а не фиксированные классы линий.

## Обучение

Скрипт обучения находится в `main.py`.  
Поддерживаются:

- CLI-параметры через `argparse`;
- валидация по `val_loss`;
- сохранение чекпоинтов `last/best/final`;
- возобновление обучения (`--resume`);
- ограничение шагов на эпоху (`--max_steps`) для быстрых экспериментов.

### Обязательные аргументы

- `--train_json`
- `--train_img_dir`
- `--val_json`
- `--val_img_dir`

### Аргументы по умолчанию

- `--epochs 10`
- `--batch_size 2`
- `--lr 1e-3`
- `--save_dir ./checkpoints`
- `--save_every 1`
- `--eval_every 1`
- `--resume ""`
- `--num_workers 2`
- `--thickness 2`
- `--line_category_id 2`
- `--max_steps 0` (`0` = полная эпоха)

### Пример запуска

```bash
python main.py \
  --train_json /path/to/annotations/train.json \
  --train_img_dir /path/to/images/train \
  --val_json /path/to/annotations/val.json \
  --val_img_dir /path/to/images/val \
  --epochs 20 \
  --batch_size 4 \
  --lr 1e-3 \
  --save_dir ./checkpoints
```

### Чекпоинты

В директории `--save_dir`:

- `ckpt_last.pt` — сохраняется каждые `--save_every` эпох;
- `ckpt_best.pt` — обновляется при улучшении `val_loss`;
- `ckpt_final.pt` — финальный сейв после завершения обучения.

## Инференс и группировка линий

Типовой пайплайн:

1. Прогнать `img` через модель и получить `emb`.
2. Взять эмбеддинги только в candidate/valid пикселях:
   `feats = emb[:, ys, xs].T` (`N x D`).
3. (Опционально) L2-нормализовать `feats`.
4. Кластеризовать `feats` (например, `DBSCAN`).
5. Собрать:
   - `pred_mask (h x w)` с ID линии;
   - словарь кластеров `cluster_id -> [(x, y), ...]`.

Ключевое преимущество: число линий определяется данными через кластеризацию, а не задается заранее.

## Зависимости

Основные библиотеки из `main.py`:

- `torch`
- `numpy`
- `opencv-python`
- `scikit-learn`
- `matplotlib` (опционально для визуализации)

